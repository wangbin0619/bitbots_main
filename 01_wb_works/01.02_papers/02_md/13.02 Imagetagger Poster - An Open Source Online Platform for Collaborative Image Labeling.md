Imagetagger:
An Open Source Online Platform for Collaborative Image Labeling
Niklas Fiedler

Hamburg Bit-Bots; Department of Informatics; University of Hamburg

Abstract

The Imagetagger is a database with integrated tools
to create and manage image data and related labels. It
was designed for the RoboCup to create training data
for neural networks and evaluation data for diverse ob-
ject recognition methods. Therefore cooperative la-
beling of the same data set, ﬂexible further use of the
images and labels and the option to share the data had
to be made possible.

Introduction
In 2016 Daniel Speck presented a neural net-
work architecture to localize balls on images in
In the future
the RoboCup environment [1].
work section he proposed to increase the train-
ing data set for better results.
The lack of sufﬁcient training data motivated
the development of the Imagetagger. As a re-
sult of providing the tool as online platform, the
exchange of image sets between teams is pro-
moted. The process of manual image labeling
has to be efﬁcient enough to label large amounts
of images.

Image Labeling

Figure 1: The labeling view consisting of the list of images, the image
itself, a list of already existing labels and the annotation tool window.

The actual labeling procedure is designed to be
as intuitive and fast as possible. Therefore the
UI is kept clean and simple with a ﬂat menu
structure. The most commonly used functions
are mapped to keyboard shortcuts to optimize
the labeling efﬁciency. A check box enables the
option to keep the selection for the next image,
which is useful when labeling a series of similar
images. The choice to label ”not in image” al-
lows the user to explicitly label the absence of an
object in an image. To support fast labeling, the
next images get preloaded so even with a slow
connection to the server the images are shown
quickly.
Already existing labels can be edited and deleted
directly in the labeling view. The bidirectional
continue buttons allow two users to traverse
through the image set towards each other.

Image Management

Figure 2: The image set management view showing the list of pictures
included in the image set, status information, a download script, an
editor for meta data and an upload area.

Export Format

To manage the large amount of images, image
sets are used. An image set consists of the im-
ages it contains and additional information about
the whole set. This information includes the lo-
cation where the images got created. On the
server side, the image sets are represented in di-
rectories (in the ﬁle system), allowing it to also
work directly on the ﬁles. Image sets are owned
by teams, thus they are allowed to edit properties
and add or delete images.

Collaboration

Figure 3: In the team view, the image sets and members are listed
with the option to add team members and create new image sets.

The Imagetagger provides features to enable a
collaboration on two levels: The members of a
team and the teams among themselves.
It of-
fers multiple options to export labels and up- or
download images which teams can use to easily
share their data set.
Every team member is able to create and edit im-
age sets owned by the team. Image sets owned
by the team can be set either private, to be only
accessible for team members, or public, which
allows all users to use the image set. This system
offers a convenient way to share the training data
while providing the possibility to keep an image
set closed for public access when needed.

Automated Labeling

The automated labeling feature is currently work
in progress. The Imagetagger offers a basis
to enable automated labeling of images. As
shown with a prototype, a large neural network
is able to detect objects, e.g. soccer balls, pre-
cise enough to create usable labels. To be able to
distribute the labeling to multiple systems and to
separate the automated labeling from the website
deployment, a REST-API could be used.

Label Veriﬁcation

Figure 4: The image set management view showing the content of the
image set, status information, a download script, an editor for meta
data and an upload area.

Labels can be veriﬁed by users to increase the
conﬁdence in them. While manually created la-
bels get veriﬁed by their creator or last editor
by default, the automatically created labels are
unveriﬁed on creation. These labels need to get
veriﬁed by a user. The amount of veriﬁcations
can be used to ﬁlter the labels.

Figure 5: To create an export format, the user has to deﬁne the name
of the format, the types of labels and the base structure of the output.

To be useful for as many approaches as possible
a ﬂexible export format is needed. Every team
has the possibility to export the labels in a format
compatible to their existing conventions. This is
achieved by the export format creator, which of-
fers a way to individually specify the format in
which annotations get exported into text ﬁles.
With the format barrier removed, the collabo-
ration among teams is possible even with com-
pletely different approaches and implementa-
tions of the use of the labels.

Conclusion
Currently the Imagetagger offers a way to man-
age and create images data sets and labels. In
the near future an option to label automatically
will be introduced to offer a way to produce a
lot of labels. Additionally it is possible to extend
the Imagetagger for labeling other types of data,
because it’s easily extendable and open source.

The code is available on GitHub:
https://github.com/bit-bots/imagetagger

References

[1] Daniel Speck. Ball localization for robocup soccer using convolu-

tional neural networks, 2016.

Acknowledgments.

Thanks to the RoboCup team Hamburg Bit-Bots. Thanks to the Server
AG and thanks to Marc Bestmann, Rebecca Glaser, Jonas Hagge,
Jennifer Meyer, Daniel Speck and Pascal Wichmann for their
cooperation and help.

